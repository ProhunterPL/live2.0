<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Figure 5: GPU Kernel Execution Diagram</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
            line-height: 1.6;
        }
        .container {
            background-color: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }
        h2 {
            color: #34495e;
            margin-top: 30px;
            border-bottom: 2px solid #ecf0f1;
            padding-bottom: 5px;
        }
        h3 {
            color: #7f8c8d;
            margin-top: 20px;
        }
        pre {
            background-color: #f8f9fa;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 15px;
            overflow-x: auto;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 13px;
            line-height: 1.4;
            white-space: pre;
        }
        code {
            background-color: #f1f3f5;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
        }
        pre code {
            background-color: transparent;
            padding: 0;
        }
        ul, ol {
            margin-left: 20px;
        }
        li {
            margin-bottom: 8px;
        }
        p {
            margin-bottom: 15px;
        }
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #ecf0f1;
            color: #7f8c8d;
            font-size: 0.9em;
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Figure 5: GPU Kernel Execution Diagram</h1>
<h2>Description</h2>
<p>Illustrates parallel execution of adaptive spatial hash rebuild and force computation on GPU.</p>
<hr>
<h2>GPU Architecture Overview</h2>
<pre><code>┌─────────────────────────────────────────────────────────────────┐
│                         GPU DEVICE                               │
│                                                                   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │               STREAMING MULTIPROCESSORS (SMs)            │   │
│  │                                                           │   │
│  │  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐│   │
│  │  │   SM 0   │  │   SM 1   │  │   SM 2   │  │   SM 3   ││   │
│  │  │          │  │          │  │          │  │          ││   │
│  │  │ 32 cores │  │ 32 cores │  │ 32 cores │  │ 32 cores ││   │
│  │  │          │  │          │  │          │  │          ││   │
│  │  └──────────┘  └──────────┘  └──────────┘  └──────────┘│   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                 GLOBAL MEMORY (GDDR6)                    │   │
│  │                                                           │   │
│  │  [positions] [attributes] [grid_cell_list]              │   │
│  │  [active] [forces] [cell_count] [adaptive_cell_size]    │   │
│  └─────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘</code></pre>
<hr>
<h2>Kernel 1: Rebuild Spatial Hash (Parallel)</h2>
<h3>Thread Assignment</h3>
<pre><code>Launch: 1024 threads (N=1000 particles, round up to block size)

Thread Grid:
┌──────────────────────────────────────────────────────────┐
│ Block 0 (256 threads)  │ Block 1 (256 threads)          │
│ ───────────────────────────────────────────────────────  │
│ T0  T1  T2  ... T255   │ T0  T1  T2  ... T255           │
│ P0  P1  P2  ... P255   │ P256 P257 P258 ... P511        │
└──────────────────────────────────────────────────────────┘
│ Block 2 (256 threads)  │ Block 3 (232 threads + 24 idle)│
│ ───────────────────────────────────────────────────────  │
│ T0  T1  T2  ... T255   │ T0  T1  T2  ... T231  [idle]   │
│ P512 P513 ... P767     │ P768 ... P999        [idle]    │
└──────────────────────────────────────────────────────────┘

Each thread processes ONE particle</code></pre>
<h3>Execution Timeline</h3>
<pre><code>Time →
0ms    1ms         2ms         3ms         4ms
│      │           │           │           │
├──────┼───────────┼───────────┼───────────┤
│                                          │
│ ┌─────────────────────────────────────┐ │
│ │ PHASE 1: Clear cell counts (GPU)    │ │ ◄── All threads cooperate
│ │   for i in parallel:                │ │
│ │     cell_count[i] = 0               │ │
│ └─────────────────────────────────────┘ │
│                                          │
│ ┌─────────────────────────────────────┐ │
│ │ PHASE 2: Hash particles (GPU)       │ │ ◄── PATENT CLAIM 2
│ │   Thread i:                         │ │     Atomic operations!
│ │     pos = positions[i]              │ │
│ │     cell = hash(pos, adaptive_s)    │ │ ◄── Uses adaptive cell_size
│ │     slot = atomic_add(count[cell])  │ │ ◄── Lock-free insertion
│ │     cell_list[cell][slot] = i       │ │
│ └─────────────────────────────────────┘ │
│                                          │</code></pre>
<h3>Atomic Operations (Thread-Safe)</h3>
<pre><code>Multiple threads may target SAME cell simultaneously:

Cell 42:
  Thread 17 → atomic_add(cell_count[42], 1) → returns 0 → slot 0
  Thread 35 → atomic_add(cell_count[42], 1) → returns 1 → slot 1
  Thread 89 → atomic_add(cell_count[42], 1) → returns 2 → slot 2
  
No race condition! Hardware ensures atomicity.

Without atomic:
  Thread 17 reads count=0, adds particle → count=1
  Thread 35 reads count=0 (race!), adds particle → count=1
  Result: Both write to slot 0, one particle lost! ❌

With atomic:
  Hardware serializes increments → guaranteed unique slots ✅</code></pre>
<hr>
<h2>Kernel 2: Compute Forces (Parallel)</h2>
<h3>Thread Assignment</h3>
<pre><code>Launch: 1024 threads (one per particle)

Thread execution:
┌────────────────────────────────────────────────┐
│ Thread i processes particle i:                 │
│                                                 │
│  1. Find particle's cell: cell_i               │
│  2. For 9 neighbor cells (3×3 stencil):        │
│       For each particle j in neighbor:         │
│         Compute force F_ij                     │
│         atomic_add(forces[i], F_ij)            │
│         atomic_add(forces[j], -F_ij)           │
└────────────────────────────────────────────────┘</code></pre>
<h3>Neighbor Search Example</h3>
<pre><code>Particle i in cell (5, 5):

Grid (adaptive cell_size = 12.0):
┌────┬────┬────┬────┬────┬────┬────┐
│    │    │    │    │    │    │    │
├────┼────┼────┼────┼────┼────┼────┤
│    │    │    │    │    │    │    │
├────┼────┼────┼────┼────┼────┼────┤
│    │    │∘∘  │∘   │∘∘  │    │    │  ◄── Row 4
├────┼────┼────┼────┼────┼────┼────┤
│    │    │∘   │●   │∘   │    │    │  ◄── Row 5 (particle i at ●)
├────┼────┼────┼────┼────┼────┼────┤
│    │    │∘∘  │∘∘  │∘   │    │    │  ◄── Row 6
├────┼────┼────┼────┼────┼────┼────┤
│    │    │    │    │    │    │    │
└────┴────┴────┴────┴────┴────┴────┘
         │    │    │
         Col 4,5,6

Check cells: [(4,4), (5,4), (6,4),
              (4,5), (5,5), (6,5),  ◄── 3×3 = 9 cells
              (4,6), (5,6), (6,6)]

Total neighbors to check: 12 particles (∘)
Actually interact: ~4-6 (within cutoff)</code></pre>
<h3>Compile-Time Loop Unrolling</h3>
<pre><code># Source code:
for dx in ti.static(range(-1, 2)):  # Compile-time constant!
    for dy in ti.static(range(-1, 2)):
        check_cell(cell_x + dx, cell_y + dy)

# Compiled GPU code (unrolled):
check_cell(cell_x - 1, cell_y - 1)
check_cell(cell_x - 1, cell_y + 0)
check_cell(cell_x - 1, cell_y + 1)
check_cell(cell_x + 0, cell_y - 1)
check_cell(cell_x + 0, cell_y + 0)  ◄── 9 explicit calls
check_cell(cell_x + 0, cell_y + 1)     NO branches!
check_cell(cell_x + 1, cell_y - 1)     NO loops!
check_cell(cell_x + 1, cell_y + 0)
check_cell(cell_x + 1, cell_y + 1)

Benefit: No branch prediction, better GPU utilization
Speedup: ~10-15% compared to dynamic loop</code></pre>
<hr>
<h2>CPU/GPU Hybrid Architecture (PATENT CLAIM 5)</h2>
<pre><code>┌─────────────────────────────────────────────────────────┐
│                     CPU (Host)                          │
│                                                          │
│  ┌────────────────────────────────────────────────┐   │
│  │ 1. Compute adaptive cell size (lightweight)    │   │ ◄── O(1)
│  │    s_new = α·√(A/N) / (1 + β·b̄)               │   │     Fast!
│  │                                                 │   │
│  │ 2. Check if rebuild needed                     │   │
│  │    if |s_new - s_old| / s_old > 0.15:         │   │
│  │      trigger_gpu_rebuild = True                │   │
│  │                                                 │   │
│  │ 3. Launch GPU kernels                          │   │
│  │    build_spatial_hash<<<blocks, threads>>>     │   │
│  │    compute_forces<<<blocks, threads>>>         │   │
│  └─────────────┬──────────────────────────────────┘   │
│                │                                        │
│                │ PCIe transfer (minimal!)              │
│                │ Only send: cell_size (1 float)        │
│                │                                        │
└────────────────┼────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────┐
│                     GPU (Device)                        │
│                                                          │
│  ┌────────────────────────────────────────────────┐   │
│  │ PERSISTENT DATA (stays on GPU):                │   │ ◄── No transfer!
│  │   - positions[N]      (8N bytes)               │   │
│  │   - attributes[N]     (16N bytes)              │   │
│  │   - forces[N]         (8N bytes)               │   │
│  │   - grid_cell_list    (350 KB)                 │   │
│  │   - cell_count        (10 KB)                  │   │
│  └────────────────────────────────────────────────┘   │
│                                                          │
│  ┌────────────────────────────────────────────────┐   │
│  │ GPU KERNELS (execute in parallel):             │   │
│  │                                                 │   │
│  │  build_spatial_hash(cell_size=s_new)           │   │ ◄── O(N)
│  │    → 1024 threads, 1-2ms                       │   │
│  │                                                 │   │
│  │  compute_forces()                              │   │ ◄── O(N)
│  │    → 1024 threads, 5-8ms                       │   │
│  │                                                 │   │
│  │  integrate_positions(dt)                       │   │ ◄── O(N)
│  │    → 1024 threads, 0.5ms                       │   │
│  └────────────────────────────────────────────────┘   │
└────────────────────────────────────────────────────────┘</code></pre>
<h3>Data Transfer Analysis</h3>
<pre><code>Traditional approach (all CPU):
  Transfer per step: 2N floats (positions + forces)
  Cost: ~0.5-1.0ms for N=1000
  Bottleneck: PCIe bandwidth

Adaptive hybrid (CPU compute, GPU work):
  Transfer per rebuild: 1 float (cell_size)
  Cost: ~0.001ms (negligible!)
  Benefit: 1000× less data transfer ✅

GPU-only (ideal but complex):
  Transfer: None (all on GPU)
  Challenge: Difficult to implement adaptive logic in kernel
  Tradeoff: Simpler to compute cell_size on CPU</code></pre>
<hr>
<h2>Memory Access Patterns</h2>
<h3>Coalesced Memory Access (GOOD)</h3>
<pre><code>Thread block accessing positions:

Memory (contiguous):
[P0][P1][P2][P3][P4][P5][P6][P7]...
 ↑   ↑   ↑   ↑   ↑   ↑   ↑   ↑
 │   │   │   │   │   │   │   │
T0  T1  T2  T3  T4  T5  T6  T7  (threads)

Result: Single 128-byte transaction ✅
Bandwidth: ~800 GB/s (full speed)</code></pre>
<h3>Non-Coalesced Access (BAD - avoided)</h3>
<pre><code>Random access pattern:

Memory:
[P0][P1][P2][P3][P4][P5][P6][P7]...
 ↑       ↑               ↑       ↑
 │       │               │       │
T0      T7              T3      T1  (scattered)

Result: 4 separate transactions ❌
Bandwidth: ~200 GB/s (1/4 speed)

Our implementation avoids this by:
- Sequential particle processing
- Cell list organized contiguously</code></pre>
<hr>
<h2>Occupancy Analysis</h2>
<pre><code>GPU: NVIDIA RTX 3080 (example)
  - 68 SMs
  - 128 cores per SM
  - 8704 cores total

Our kernel:
  - Block size: 256 threads
  - Registers per thread: ~32
  - Shared memory: 0 KB (uses global only)
  
Occupancy:
  Blocks per SM: 4 (limited by registers)
  Threads per SM: 1024
  Total active threads: 68 × 1024 = 69,632
  
For N=1000 particles:
  Active threads: 1024 (padded from 1000)
  Utilized SMs: 4 (out of 68)
  Occupancy: 5.9% (low for small N)
  
For N=10000 particles:
  Active threads: 10,240
  Utilized SMs: 40 (out of 68)
  Occupancy: 58.8% (much better!)
  
Scaling: Performance improves with larger N</code></pre>
<hr>
<h2>Patent Claim Support</h2>
<p>This figure demonstrates:</p>
<ul>
<li><strong>Claim 2</strong>: GPU implementation with lock-free atomic operations</li>
<li><strong>Claim 5</strong>: Hybrid CPU/GPU architecture with minimal data transfer</li>
<li><strong>Innovation</strong>: Compile-time loop unrolling for fixed 3×3 stencil</li>
<li><strong>Innovation</strong>: Coalesced memory access for high bandwidth</li>
<li><strong>Innovation</strong>: Adaptive cell size computed on CPU, used by GPU kernels</li>
</ul>
<hr>
<h2>Key Innovations Summary</h2>
<ol>
<li>✅ <strong>Lock-free atomic insertions</strong> - Thread-safe without locks</li>
<li>✅ <strong>Compile-time loop unrolling</strong> - Eliminates branch overhead</li>
<li>✅ <strong>Persistent GPU memory</strong> - Minimal data transfer</li>
<li>✅ <strong>Hybrid architecture</strong> - CPU computes, GPU executes</li>
<li>✅ <strong>Coalesced access patterns</strong> - Full memory bandwidth</li>
<li>✅ <strong>Scalable occupancy</strong> - Better utilization for larger systems</li>
</ol>
        <div class="footer">
            <p>Generated from: FIGURE_5_gpu_execution.md</p>
        </div>
    </div>
</body>
</html>
